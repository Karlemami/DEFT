\section{Discussion et Conclusion}

Les résultats montrent que, sur ce corpus, les vecteurs qui donnent les meilleurs classifieurs sont finalement les moins complexes et les moins denses, c'est-à-dire, les vecteurs \texttt{TF-IDF}. Cela peut s'expliquer de plusieurs façons. Une première raison peut être la nature même des données étudiées : les données de discours du parlement européens sont spécialisée, et contiennent nécessairement des mots relatifs au domaine. Or, \texttt{BERT} est entrainé sur un corpus général. On pourrait envisager de le fine-tuner afin d'obtenir de meilleurs résultats.  \footnote{Il existe également un modèle spécialisé sur le domaine légal, nommé \texttt{LEGAL-BERT}, mais il n'est entraîné que sur l'anglais. Cela pourrait toutefois constituer une recherche ultérieure.} En revanche, le vectoriseur \texttt{TF-IDF} s'adapte au vocabulaire juridique spécifique à ce type de document. Par ailleurs, on peut supposer que la taille relativement réduite des documents peut être à l'origine de la mauvaise qualité des vecteurs obtenus, non seulement avec \texttt{BERT} mais aussi avec \texttt{Doc2Vec}. De plus, les classifieurs que nous lançons sur nos données sont des classifieurs simples, linéaires ou sous forme arbres de décision. Or, les vecteurs complexes générés par réseaux de neurones pourraient nécessiter un réseau de neurones pour la classification ensuite; cela pourrait constituer une perspective pour poursuivre notre expérience. Nous pourrions également imaginer des approches hybrides, qui combineraient les features \texttt{TF-IDF} avec des embeddings \texttt{BERT} pour capturer autant d'informations que nécessaires. De plus, afin d'améliorer les résultats, nous avons envisagé de lancer une \texttt{Grid Seach} pour tuner les hyperparamètres de chacun des classifieurs, mais après quelques tests, le coût computationnel n'a pas su être compensé par une amélioration suffisante de la f-mesure.\footnote{Nous l'avons laissée dans le code malgré tout et il est toujours possible de la faire tourner sur l'ensemble des classifieurs \textit{(cf. \texttt{README.md})}.} Enfin, on remarque que les résultats sont relativement homogènes entre les 3 langues, avec des performances légèrement meilleures pour l'anglais et légèrement en-dessous pour l'italien. 
