\section{Discussion et Conclusion}

Ces résultats montrent que, sur ce corpus, les vecteurs qui donnent les meilleurs classifieurs sont finalement les plus simples, les vecteurs \texttt{TF-IDF}. Cela peut s'expliquer de plusieurs façons. Tout d'abord, les données étudiées donnent une explication de ces performances : les données de discours du parlement européens sont de nature spécialisée, et contiennent nécessairement des mots spécialisés au domaine. Or, Bert est entrainé sur un corpus général. Il faudrait le fine-tuner afin d'obtenir de meilleurs résultats. En revanche, le vectoriseur tf-idf s'adapte aux mots de vocabulaire spécifique à ce type de document. Par ailleurs, on peut noter que la taille très réduite des documents peut être à l'origine de la mauvaise qualité des vecteurs obtenus, non seulement avec BERT mais aussi avec doc2vec. De plus, les classifieurs que nous lançons sur nos données sont des classifieurs simples, linéaires ou arbres. Or, les vecteurs complexes générés par réseaux de neurones pourraient nécessiter un réseau de neurones pour la classification ensuite; cela pourrait constituer une perspective pour poursuivre notre expérience. Nous pourrions également imaginer des approches hybrides, qui combineraient les features TF-IDF avec des embeddings BERT pour capturer autant d'informations que nécessaires.